{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_ET_Time_Value_Table(mapping_pkl_path,rz_node_order_file_path,coupled_mod_hgs_dir,coupled_mod_dssat_dir):\n",
    "    \"\"\"Build the daily ET Time Value tables, to bring DSSAT evaporation outputs into HGS\n",
    "\n",
    "    Parameters:\n",
    "    mapping_pkl_path (str): path to pickle file containing mapping information\n",
    "    rz_node_order_file_path (str): path to file containing the order of HGS nodes in the root zone\n",
    "    coupled_mod_hgs_dir (str): path to coupled model HGS subdirectory\n",
    "    coupled_mod_dssat_dir (str): path to coupled model DSSAT subdirectory\n",
    "        \n",
    "            \n",
    "    Returns:\n",
    "\n",
    "   \"\"\"\n",
    "    # Load node list\n",
    "    with open(rz_node_order_file_path,'r') as file:\n",
    "        lines = file.readlines()\n",
    "    nodes = [int(x.strip()) for x in lines]\n",
    "    # Load mapping pickle\n",
    "    with open(mapping_pkl_path,'rb') as file:\n",
    "        map_dict = pkl.load(file)\n",
    "    for day in range(275):\n",
    "        # Blank list for vals\n",
    "        vals = []\n",
    "        # Load CSV's\n",
    "        # Identify path to DSSAT Surface ET file\n",
    "        surface_data_path = os.path.join(coupled_mod_dssat_dir,'Full_SurfaceET.txt')\n",
    "        # Load\n",
    "        surface_data = pd.read_csv(surface_data_path, sep = '\\s+')['EOAA'].values\n",
    "        # Identify path to DSSAT Soil ET file\n",
    "        soil_data_path = os.path.join(coupled_mod_dssat_dir,'Full_SoilET.txt')\n",
    "        # Load\n",
    "        soil_data = pd.read_csv(soil_data_path, sep = '\\s+')\n",
    "        # Iterate through nodes\n",
    "        for node in nodes:\n",
    "            # Get DSSAT location information\n",
    "            dssat_model,sheet,area_stat = map_dict[node]\n",
    "            # Get surface ET and half of soil layer 1 for sheet 0\n",
    "            if sheet == 0:\n",
    "                # Grab val up from surface file\n",
    "                valup = surface_data[day]\n",
    "                # Grab val down from soil file layer 1\n",
    "                valdn = soil_data['ES{}D'.format(sheet + 1)].values[day]\n",
    "                # Set value to full surface ET + 1/2 of layer 1 ET\n",
    "                val = (valup + (0.5*valdn)) * -1 * 24. * 60. / 1000. * (1./area_stat)\n",
    "            # For bottom node sheet, just get half of last DSSAT layer\n",
    "            elif sheet == 10:\n",
    "                # Grab val down from soil file layer 1\n",
    "                valup = soil_data['ES{}D'.format(sheet)].values[0]\n",
    "                # Set value to 1/2 of layer 10 ET\n",
    "                val = ((0.5*valup)) * -1 * 24. * 60. / 1000. * (1./area_stat)\n",
    "            # For all other sheets, take half of layer above and half of layer below\n",
    "            else:\n",
    "                # Grab val down from soil file layer 1\n",
    "                valup = soil_data['ES{}D'.format(sheet)].values[0]\n",
    "                # Grab val down from soil file layer 1\n",
    "                valdn = soil_data['ES{}D'.format(sheet + 1)].values[0]\n",
    "                # Set value to 1/2 of layer n ET and 1/2 of layer n+1 ET\n",
    "                val = ((0.5*valdn) + (0.5*valup)) * -1 * 24. * 60. / 1000. * (1./area_stat)\n",
    "            # Convert DSSAT total mm to HGS total m3 and then multiply by minutes in a day to force all to be taken out in first minute of day\n",
    "            vals.append(val)\n",
    "        # Write out nflux.txt file\n",
    "        nflux_path = os.path.join(coupled_mod_hgs_dir,'n{}flux.txt'.format(day))\n",
    "        with open(nflux_path,'w') as file:\n",
    "            file.write(str(len(vals))+'\\n')\n",
    "            lines = []\n",
    "            for val in vals:\n",
    "                lines.append(str(val)+'\\n')\n",
    "            lines[-1] = lines[-1][:-1]\n",
    "            for line in lines:\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish params\n",
    "mapping_pkl_path = r'C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys\\mapping\\lys_node_mapping.p'\n",
    "rz_node_order_file_path = r'C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys\\hgs\\rz_node_order.txt'\n",
    "coupled_mod_hgs_dir = r'C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys\\hgs'\n",
    "coupled_mod_dssat_dir = r'C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\data_dssat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Build_ET_Time_Value_Table(mapping_pkl_path,rz_node_order_file_path,coupled_mod_hgs_dir,coupled_mod_dssat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
