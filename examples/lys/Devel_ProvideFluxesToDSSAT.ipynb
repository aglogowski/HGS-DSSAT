{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dir = r'C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgs_mod_dir = os.path.join(mod_dir,'hgs')\n",
    "model_name = 'lys'\n",
    "grok_file_path = os.path.join(hgs_mod_dir,model_name + '_e.grok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grok_file_stem = model_name + '_e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_mapping_pkl_path = r'C:\\\\Users\\\\southa0000\\\\Documents\\\\HGS-DSSAT\\\\HGS-DSSAT\\\\examples\\\\lys\\\\mapping\\\\lys_elem_mapping.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateCoupledModelDir(mod_dir):\n",
    "    # Create directories if they don't exist\n",
    "    coupled_mod_dir = os.path.join(mod_dir,'coupled')\n",
    "    try:\n",
    "        os.mkdir(coupled_mod_dir)\n",
    "    except:\n",
    "        print(coupled_mod_dir + ' already exists')\n",
    "    # Create hgs subdirectory\n",
    "    coupled_mod_hgs_dir = os.path.join(coupled_mod_dir,'hgs')\n",
    "    try:\n",
    "        os.mkdir(coupled_mod_hgs_dir)\n",
    "    except:\n",
    "        print(coupled_mod_hgs_dir + ' already exists')\n",
    "    # Create dssat subdirectory\n",
    "    coupled_mod_dssat_dir = os.path.join(coupled_mod_dir,'dssat')\n",
    "    try:\n",
    "        os.mkdir(coupled_mod_dssat_dir)\n",
    "    except:\n",
    "        print(coupled_mod_dssat_dir + ' already exists')\n",
    "    return coupled_mod_dir,coupled_mod_hgs_dir,coupled_mod_dssat_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys\\coupled already exists\n",
      "C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys\\coupled\\hgs already exists\n",
      "C:\\Users\\southa0000\\Documents\\HGS-DSSAT\\HGS-DSSAT\\examples\\lys\\coupled\\dssat already exists\n"
     ]
    }
   ],
   "source": [
    "# Create Directory Structure\n",
    "cmod_dir,cmod_hgs_dir,cmod_dssat_dir = CreateCoupledModelDir(mod_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDailyFluxFiles(e_mapping_pkl_path,coupled_mod_dssat_dir,coupled_mod_hgs_dir,grok_file_stem,day):\n",
    "    # # Get pm file path\n",
    "    # pm_file = grok_file_stem.split('_')[0] + '_eday{}o.pm.dat'.format(day-1)\n",
    "    pm_file = grok_file_stem.split('_')[0] + '_eo.pm.dat'\n",
    "    pm_file_path = os.path.join(coupled_mod_hgs_dir,pm_file)\n",
    "    # Load mapping pickle\n",
    "    with open(e_mapping_pkl_path,'rb') as file:\n",
    "        map_dict = pkl.load(file)\n",
    "    # Load lines\n",
    "    with open(pm_file_path,'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # # Get last entry in file for solution time = 1\n",
    "    # start = [i for i, line in enumerate(lines) if 'SOLUTIONTIME=1.00000000000000' in line][0]\n",
    "    # Get entry in file for solution time = day\n",
    "    start = [i for i, line in enumerate(lines) if 'SOLUTIONTIME={}.'.format(day) in line][0]\n",
    "    # Get indexes for start and end of z flux section\n",
    "    st1lines = lines[start:]\n",
    "    start_z = st1lines.index('# z flux (cell centred)\\n')\n",
    "    sub_lines = st1lines[start_z:]\n",
    "    inds = [i for i, line in enumerate(sub_lines) if '#' in line]\n",
    "    zlines = sub_lines[inds[0]+1:inds[1]]\n",
    "    hgs_z_vals = []\n",
    "    for line in zlines:\n",
    "        for num in line.strip().split():\n",
    "            hgs_z_vals.append(float(num))\n",
    "    # Get lists of dssat models and layers\n",
    "    dssat_models = set([map_dict[x][0] for x in map_dict.keys()])\n",
    "    layers = set([map_dict[x][1] for x in map_dict.keys()])\n",
    "    # For each dssat model, grab a list of elements for each layer\n",
    "    els_dict = {}\n",
    "    for mdl in dssat_models:\n",
    "        els_dict[mdl] = []\n",
    "        for layer in layers:\n",
    "            for el in map_dict.keys():\n",
    "                if map_dict[el] == [mdl,layer]:\n",
    "                    els_dict[mdl].append(el)\n",
    "                    break\n",
    "        # Construct z val list\n",
    "        z_vals = []\n",
    "        for el in els_dict[mdl]:\n",
    "            z_vals.append(-1*hgs_z_vals[-1*el]*100.)\n",
    "        # Write out to file\n",
    "        drn_path = os.path.join(coupled_mod_dssat_dir,'{}_{}_DRN.inp'.format(mdl,day))\n",
    "        with open(drn_path,'w') as file:\n",
    "            line = ''\n",
    "            for val in z_vals:\n",
    "                line += (f\"{val:7.4f}\"+'   ')\n",
    "            for i in np.arange(0,10):\n",
    "                line += (\"0.0000\"+'   ')\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Flux Files\n",
    "for day in np.arange(1,276):\n",
    "    BuildDailyFluxFiles(e_mapping_pkl_path,cmod_dssat_dir,cmod_hgs_dir,grok_file_stem,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
